from typing import Any, Callable, Dict, List, Union

from scripts.memory import Memory


def remove_thinking_sections(text: str) -> str:
    """
    Removes any text between <think> and </think> tags from model outputs.

    Args:
        text (str): The text potentially containing thinking sections.

    Returns:
        str: The cleaned text with thinking sections removed.
    """
    if text is None:
        return ""

    import re

    # Remove all content between <think> and </think> tags (including the tags)
    cleaned_text = re.sub(r"<think>.*?</think>", "", text, flags=re.DOTALL)
    return cleaned_text.strip()


def format_history(history: List) -> str:
    """This function formats the history of the game in line with the original SmartPlay paper.

    Instead of a a list of tuples like in RL (s, a, r, s', d)
    ('A new round begins.', 'Pull slot machine 1.', -1, 'You pulled slot machine 1, you received reward -1.', False),

    The history is formatted like below in the paper:

    Player Observation Step {step number}: {observation}, you received reward {reward}

    """

    formatted_history = []
    for i, (observation, action, reward, next_state, done) in enumerate(history):
        formatted_history.append(f"Player Observation Step {i + 1}:\n{observation}")
    return "\n\n".join(formatted_history)


def load_prompt_template(template_path: str) -> str:
    """
    Load the template file as a string.

    Args:
        template_path (str): The path to the template file.

    Returns:
        str: The content of the template file as a string.
    """
    with open(template_path, "r") as file:
        template = file.read()
    return template


def compose_ingame_prompt(
    info: Dict[str, Any],
    trajectory: List,
    template_path: str,
    model_type: str = "openai",
    reflection_output: str = None,
    oracle_output: str = None,
    planner_output: str = None,
    reflections_string: str = None,
    use_history_format_paper: bool = True,
) -> Union[List[Dict[str, str]], str]:
    """
    Composes a prompt for the LLM to answer a question in the context of a game.

    Args:
        info (Dict[str, Any]): The game information.
        trajectory (List[Tuple[str, int, int, str, int]]): The trajectory of the game.
        template_path (str): The path to the template file.
        model_type (str): The type of model (e.g., "openai" or "huggingface").
        reflection_output (str): The output generated by the reflection.
        oracle_output (str): The output generated by the Oracle.
        planner_output (str): The output generated by the planner.
        reflections_string (str): The string representation of the reflections.
        format_history (bool): Whether to format the history like in the SmartPlay paper. See function for more details.

    Returns:
        Union[List[Dict[str, str]], str]: The prompt as a list of messages for OpenAI API or as a string for Hugging Face API

    """

    # Whether to format the history like in the SmartPlay paper
    if use_history_format_paper:
        trajectory = format_history(trajectory)

    # Load the template as a string
    template = load_prompt_template(template_path)

    # Clean outputs by removing thinking sections
    # This is needed for deepseek models
    clean_reflection_output = remove_thinking_sections(reflection_output)
    clean_oracle_output = remove_thinking_sections(oracle_output)
    clean_planner_output = remove_thinking_sections(planner_output)
    clean_reflections_string = remove_thinking_sections(reflections_string)

    # Build the dictionary for formatting the template
    format_dict = {
        "manual": info.get("manual", "No manual available"),
        "trajectory": trajectory,
        "obs": info.get("obs", "No observation available"),
        "question": "What is the next action to take, let's think step by step",
        "reflection_output": clean_reflection_output or "",
        "reflections_string": clean_reflections_string or "",
        "oracle_output": clean_oracle_output or "",
        "planner_output": clean_planner_output or "",
    }

    # Render the prompt using string formatting
    prompt = template.format(**format_dict)

    if model_type not in [
        "openai",
        "huggingface",
        "local_huggingface",
        "ollama",
        "gemini",
        "deepseek",
    ]:
        raise ValueError(
            "Unsupported model type. Choose 'openai', 'huggingface', 'local_huggingface', 'ollama', 'gemini', or 'deepseek'."
        )

    if model_type == "openai":
        messages = [{"role": "system", "content": prompt}]
        return messages

    else:
        return prompt


def get_reflection_output(
    info: Dict[str, Any], trajectory: List, model_type: str, query_model: Callable
) -> str:
    """
    Generates the reflection's output based on the given trajectory.

    Args:
        info (Dict[str, Any]): The game information.
        trajectory (List[Tuple[str, int, int, str, bool, int]]): The trajectory of the game.
        model_type (str): The type of model (e.g., "openai" or "huggingface").
        query_model (Callable): The function to query the model.

    Returns:
        str: The output generated by the reflection.
    """
    # Compose reflection prompt and query the reflection for heuristics
    reflection_prompt = compose_ingame_prompt(
        info=info,
        trajectory=trajectory,
        model_type=model_type,
        template_path="src/prompts/reflection.txt",
    )
    reflection_output = query_model(reflection_prompt)
    return reflection_output[0]


def get_oracle_output(
    info: Dict[str, Any],
    memory: Memory,
    n_reflections: int,
    model_type: str,
    query_model: Callable,
) -> str:
    """
    Generates the Oracle's output based on the last N reflections from memory.

    Args:
        info (Dict[str, Any]): The game information.
        memory (Memory): The memory object containing reflections.
        n_reflections (int): Number of reflections to use.
        model_type (str): The type of model (e.g., "openai" or "huggingface").
        query_model (Callable): The function to query the model.

    Returns:
        str: The output generated by the Oracle.
    """

    # Retrieve the last N reflections from memory
    reflections = memory.get_reflections(n=n_reflections)

    # Concatenate the reflections into a single string
    reflections_string = "\n".join(reflections)

    # Compose Oracle prompt and query the Oracle for heuristics
    oracle_prompt = compose_ingame_prompt(
        info=info,
        trajectory=[],
        model_type=model_type,
        reflection_output=reflections_string,
        reflections_string=reflections_string,
        template_path="src/prompts/oracle.txt",
    )

    oracle_output = query_model(oracle_prompt, temperature=1.0)
    return oracle_output[0]


def get_planner_output(
    info: Dict[str, Any],
    trajectory: List,
    model_type: str,
    query_model: Callable,
    reflection_output: str,
) -> str:
    """
    Prompt the planner to generate the next action based on its predictions
    """
    # Compose reflection prompt and query the reflection for heuristics
    planner_prompt = compose_ingame_prompt(
        info=info,
        trajectory=trajectory,
        model_type=model_type,
        reflection_output=reflection_output,
        template_path="src/prompts/planner.txt",
    )
    planner_output = query_model(planner_prompt)
    return planner_prompt, planner_output[0]


def generate_agent_prompt(
    info: Dict[str, Any],
    trajectory: List,
    model_type: str,
    use_reflection_template: bool,
    step_number: int,
    reflection_start_step: int,
    reflection_output: str = None,
    use_oracle_template: bool = False,
    oracle_output: str = None,
    planner_output: str = None,
) -> str:
    """
    Generates the appropriate prompt for the agent, optionally incorporating reflection and Oracle outputs.

    Args:
        info (Dict[str, Any]): The game information.
        trajectory (List[Tuple[str, int, int, str, bool, int]]): The trajectory of the game.
        model_type (str): The type of model (e.g., "openai" or "huggingface").
        use_reflection_template (bool): Whether to use a reflection template.
        step_number (int): The current step number.
        reflection_start_step (int): The step number to start using reflection.
        reflection_output (str): The output from reflection, if any.
        use_oracle_template (bool): Whether to use an oracle template.
        oracle_output (str): The output from the oracle, if any.
        planner_output (str): The output from the planner, if any.
        use_planner_template (bool): Whether to use a planner template.

    Returns:
        str: The generated prompt for the agent.
    """

    # Only reflection is used
    if (
        not use_oracle_template
        and use_reflection_template
        and step_number >= reflection_start_step
    ):
        # Compose the agent prompt using only the reflection's output
        prompt = compose_ingame_prompt(
            info=info,
            trajectory=trajectory,
            model_type=model_type,
            reflection_output=reflection_output,
            template_path="src/prompts/agent_with_reflection.txt",
        )
    # Reflection and Oracle are used
    elif (
        use_oracle_template
        and use_reflection_template
        and step_number >= reflection_start_step
        and not planner_output
    ):

        # Compose the agent prompt using both reflection's and Oracle's output
        prompt = compose_ingame_prompt(
            info=info,
            trajectory=trajectory,
            model_type=model_type,
            reflection_output=reflection_output,
            oracle_output=(
                oracle_output[0] if isinstance(oracle_output, tuple) else oracle_output
            ),
            template_path="src/prompts/agent_with_reflection_and_oracle.txt",
        )
    else:
        # No reflection or oracle are used
        prompt = compose_ingame_prompt(
            info=info,
            trajectory=trajectory,
            model_type=model_type,
            template_path="src/prompts/agent.txt",
        )

    return prompt
